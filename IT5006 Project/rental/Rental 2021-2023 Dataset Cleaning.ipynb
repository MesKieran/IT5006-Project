{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5633aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"Original/RentingOutofFlats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3baad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c89c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\"\"\"\n",
    "print(df.duplicated().sum()) # number of duplicated rows that should be removed\n",
    "df_dup = df[df.duplicated()] # df showing the duplicated rows that should be removed\n",
    "df_dup.head()\n",
    "\"\"\"\n",
    "\n",
    "# Remove duplicates\n",
    "df_cleaned = df.drop_duplicates(subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d430b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to appropriate data type\n",
    "#df_cleaned.dtypes\n",
    "\n",
    "df_cleaned = df_cleaned.astype('string')\n",
    "\n",
    "df_cleaned['monthly_rent'] = df_cleaned['monthly_rent'].astype('int32')\n",
    "df_cleaned['rent_approval_date'] = pd.to_datetime(df_cleaned['rent_approval_date'])\n",
    "#df_cleaned['rent_approval_date'] = df_cleaned['rent_approval_date'].dt.to_period('M')\n",
    "\n",
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30454fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency in categories\n",
    "for col in ['town', 'flat_type']:\n",
    "    print(f'{col}:', sorted(df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers (but not removing them)\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True)\n",
    "\n",
    "flats = sorted(df['flat_type'].unique())\n",
    "for index, flat in enumerate(flats):\n",
    "    a = index//3\n",
    "    b = index%3\n",
    "    flat_data = df_cleaned[df_cleaned['flat_type'] == flat]\n",
    "    ax[a, b].boxplot(flat_data['monthly_rent'])\n",
    "    ax[a, b].set_title(flat)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Despite the super wide range of values, data seems to be for whole flats and not just one bedroom.\n",
    "# References: \n",
    "# - https://services2.hdb.gov.sg/webapp/BR12AWRentalEnq/BR12PSearch.jsp (for rental of whole flats - checked that certain outliers are in here)\n",
    "# - https://www.hdb.gov.sg/residential/renting-a-flat/renting-from-the-open-market/rental-statistics (median prices from dataset match these - mostly within $50 deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1145b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many outliers? (using IQR method)\n",
    "Q1 = df_cleaned['monthly_rent'].quantile(0.25)\n",
    "Q3 = df_cleaned['monthly_rent'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df_cleaned[(df_cleaned['monthly_rent'] < lower_bound) | (df_cleaned['monthly_rent'] > upper_bound)]\n",
    "print(f'Outliers: {outliers.shape[0]} ({100*outliers.shape[0]/df_cleaned.shape[0]:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lat, lng\n",
    "hdb_locations = pd.read_csv('Additional/sg_zipcode_mapper_utf.csv')\n",
    "hdb_locations = hdb_locations.loc[hdb_locations['postal'] == hdb_locations['postal.1']]\n",
    "hdb_locations.drop(['Unnamed: 0', 'postal', 'searchval', 'building', 'address', 'postal.1'], axis='columns', inplace=True)\n",
    "\n",
    "df_cne = df_cleaned.merge(hdb_locations, on=['block', 'street_name'], how='left')\n",
    "df_cne.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing lat, lng data\n",
    "missing = df_cne[df_cne['lat'].isnull()]\n",
    "missing.to_csv('missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98d1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Impute missing lat, lng data (https://www.geoapify.com/tools/geocoding-online)\n",
    "geoapify = pd.read_csv('Additional/missing_geoapify.csv')\n",
    "df_cne = df_cne.merge(geoapify, on=['block', 'street_name'], how='left', suffixes=(None, '_geo'))\n",
    "df_cne['lat'] = df_cne['lat'].fillna(df_cne['lat_geo'])\n",
    "df_cne['lng'] = df_cne['lng'].fillna(df_cne['lng_geo'])\n",
    "df_cne.drop(['lat_geo', 'lng_geo'], axis='columns', inplace=True)\n",
    "\n",
    "df_cne.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for nearest MRT\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "def earth_distance(x, y):\n",
    "\n",
    "  # Approximate radius of earth in km\n",
    "  R = 6373.0\n",
    "\n",
    "  lat1, lng1 = radians(x[0]), radians(x[1])\n",
    "  lat2, lng2 = radians(y[0]), radians(y[1])\n",
    "\n",
    "  dlon = lng2 - lng1\n",
    "  dlat = lat2 - lat1\n",
    "\n",
    "  a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "  c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "  return R * c\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "  dx = x[0] - y[0]\n",
    "  dy = x[1] - y[1]\n",
    "\n",
    "  return sqrt(dx**2 + dy**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nearest MRT\n",
    "mrt_locations = pd.read_csv(\"Additional/mrt_data.csv\")\n",
    "mrt_locations.drop(columns=['type'], inplace=True)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = mrt_locations.drop('station_name', axis=1)\n",
    "y = mrt_locations['station_name']\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "df_cne['nearest_mrt'] = knn.predict(df_cne[['lat', 'lng']])\n",
    "\n",
    "df_cne = df_cne.merge(mrt_locations, left_on='nearest_mrt', right_on='station_name', how='left', suffixes=(None, '_mrt'))\n",
    "df_cne['mrt_dist'] = df_cne.apply(lambda row: earth_distance([row.lat_mrt, row.lng_mrt], [row.lat, row.lng]), axis=1)\n",
    "df_cne.drop(['lat_mrt', 'lng_mrt', 'station_name'], axis='columns', inplace=True)\n",
    "df_cne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0622ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import resale dataset\n",
    "\"\"\"resale_df = pd.DataFrame()\n",
    "csv_files = ['Original/ResaleFlatPricesBasedonApprovalDate19901999.csv',\n",
    "            'Original/ResaleFlatPricesBasedonApprovalDate2000Feb2012.csv',\n",
    "            'Original/ResaleFlatPricesBasedonRegistrationDateFromMar2012toDec2014.csv',\n",
    "            'Original/ResaleFlatPricesBasedonRegistrationDateFromJan2015toDec2016.csv',\n",
    "            'Original/ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv']\n",
    " \n",
    "for file in csv_files:\n",
    "    df_temp = pd.read_csv(file)\n",
    "    resale_df = pd.concat([resale_df, df_temp], ignore_index=True)\"\"\"\n",
    "\n",
    "# Rewritten cuz original resale files too big to upload\n",
    "resale_df = pd.read_csv('Original/resale_df1.csv')\n",
    "df_temp = pd.read_csv('Original/resale_df2.csv')\n",
    "resale_df = pd.concat([resale_df, df_temp], ignore_index=True)\n",
    "\n",
    "resale_df['flat_type'] = resale_df['flat_type'].str.replace(' ROOM', '-ROOM')\n",
    "resale_df.drop_duplicates(subset=None, inplace=True)\n",
    "resale_df.drop(['month', 'storey_range', 'flat_model', 'remaining_lease', 'resale_price'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff837b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try to enrich using resale dataset - floor area & flat age\n",
    "# Match to flat_type, block, and street_name\n",
    "resale_median = pd.DataFrame(resale_df.groupby(['flat_type', 'block', 'street_name']).median())\n",
    "df_cne2 = df_cne.merge(resale_median, on=['flat_type', 'block', 'street_name'], how='left', suffixes=(None, '_1'))\n",
    "\n",
    "# Fill missing lease_commence_date values using median of data with same block & street_name\n",
    "resale_copy = resale_df.drop_duplicates(subset=['block', 'street_name'], inplace=False)\n",
    "df_cne2 = df_cne2.merge(resale_copy, on=['block', 'street_name'], how='left', suffixes=(None, '_2'))\n",
    "df_cne2['lease_commence_date'] = df_cne2['lease_commence_date'].fillna(df_cne2['lease_commence_date_2'])\n",
    "df_cne2.drop(['floor_area_sqm_2', 'lease_commence_date_2', 'town_2', 'flat_type_2'], axis='columns', inplace=True)\n",
    "\n",
    "# Can't fill missing lease_commence_date values using median of data with same street_name because variation can be quite large\n",
    "# Can't fill missing floor_area_sqm values using median of data with same flat_type & street_name because variation can be quite large\n",
    "# Python libraries typically exclude data points with missing data in the columns involved in the plot\n",
    "# Therefore, can ignore small % of missing values in the additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cne2.shape)\n",
    "df_cne2.isnull().sum() # can ignore small % of missing values in the additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cne2.to_csv('rental_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
